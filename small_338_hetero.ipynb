{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\agavr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\typing.py:72: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: [WinError 127] The specified procedure could not be found\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "c:\\Users\\agavr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\typing.py:110: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: [WinError 127] The specified procedure could not be found\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  drug={ x=[338, 467] },\n",
      "  drug_category={ x=[1095, 1095] },\n",
      "  atc_code={ x=[974, 974] },\n",
      "  target={ x=[249, 249] },\n",
      "  doping={ x=[2, 2] },\n",
      "  (drug, isInCategory, drug_category)={ edge_index=[2, 8347] },\n",
      "  (drug, isClassifiedAs, atc_code)={ edge_index=[2, 2229] },\n",
      "  (drug, targets, target)={ edge_index=[2, 338] },\n",
      "  (drug, isDoping, doping)={ edge_index=[2, 338] },\n",
      "  (drug, interactsWith, drug)={ edge_index=[2, 41415] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "# Load encoded data from CSV files\n",
    "encoded_drugbank_id_df = pd.read_csv('encoders_small/encoded_drugbank_id.csv')\n",
    "encoded_name_df = pd.read_csv('encoders_small/encoded_name.csv')\n",
    "encoded_state_df = pd.read_csv('encoders_small/encoded_state.csv')\n",
    "encoded_groups_df = pd.read_csv('encoders_small/encoded_groups.csv')\n",
    "encoded_categories_df = pd.read_csv('encoders_small/encoded_categories.csv')\n",
    "encoded_atc_codes_df = pd.read_csv('encoders_small/encoded_atc_codes.csv')\n",
    "encoded_targets_df = pd.read_csv('encoders_small/encoded_targets.csv')\n",
    "encoded_interactions_df = pd.read_csv('encoders_small/encoded_interactions.csv')\n",
    "encoded_molecular_formula_df = pd.read_csv('encoders_small/encoded_molecular_formula.csv')\n",
    "encoded_doping_df = pd.read_csv('encoders_small/encoded_doping.csv')\n",
    "\n",
    "# Convert DataFrames to tensors\n",
    "encoded_drugbank_id_tensor_1 = torch.tensor(encoded_drugbank_id_df.values, dtype=torch.float32)\n",
    "encoded_name_tensor_1 = torch.tensor(encoded_name_df.values, dtype=torch.float32)\n",
    "encoded_state_tensor_1 = torch.tensor(encoded_state_df.values, dtype=torch.float32)\n",
    "encoded_groups_tensor_1 = torch.tensor(encoded_groups_df.values, dtype=torch.float32)\n",
    "encoded_categories_tensor_1 = torch.tensor(encoded_categories_df.values, dtype=torch.float32)\n",
    "encoded_atc_codes_tensor_1 = torch.tensor(encoded_atc_codes_df.values, dtype=torch.float32)\n",
    "encoded_targets_tensor_1 = torch.tensor(encoded_targets_df.values, dtype=torch.float32)\n",
    "encoded_interactions_tensor_1 = torch.tensor(encoded_interactions_df.values, dtype=torch.float32)\n",
    "encoded_molecular_formula_tensor_1 = torch.tensor(encoded_molecular_formula_df.values, dtype=torch.float32)\n",
    "encoded_doping_tensor_1 = torch.tensor(encoded_doping_df.values, dtype=torch.float32)\n",
    "\n",
    "# Initialize HeteroData\n",
    "data_small = HeteroData()\n",
    "\n",
    "# Add Drug node features\n",
    "data_small['drug'].x = torch.cat([\n",
    "    encoded_drugbank_id_tensor_1,\n",
    "    encoded_name_tensor_1,\n",
    "    encoded_state_tensor_1,\n",
    "    encoded_groups_tensor_1,\n",
    "    encoded_molecular_formula_tensor_1\n",
    "], dim=1)\n",
    "\n",
    "# Add Drug Category nodes (one-hot encoding)\n",
    "data_small['drug_category'].x = torch.eye(len(encoded_categories_df.columns), dtype=torch.float32)\n",
    "\n",
    "# Add ATC Code nodes (one-hot encoding)\n",
    "data_small['atc_code'].x = torch.eye(len(encoded_atc_codes_df.columns), dtype=torch.float32)\n",
    "\n",
    "# Add Target nodes (one-hot encoding)\n",
    "data_small['target'].x = torch.eye(len(encoded_targets_df.columns), dtype=torch.float32)\n",
    "\n",
    "# Add Doping nodes (one-hot encoding)\n",
    "data_small['doping'].x = torch.eye(len(encoded_doping_df['Doping'].unique()), dtype=torch.float32)\n",
    "\n",
    "# Create edge lists for drug-to-category relationships\n",
    "source_nodes = []\n",
    "target_nodes = []\n",
    "for drug_idx, row in encoded_categories_df.iterrows():\n",
    "    for category_idx in range(len(row)):\n",
    "        if row[category_idx] == 1:\n",
    "            source_nodes.append(drug_idx)\n",
    "            target_nodes.append(category_idx)\n",
    "data_small['drug', 'isInCategory', 'drug_category'].edge_index = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "\n",
    "# Create edge lists for drug-to-ATC code relationships\n",
    "source_nodes = []\n",
    "target_nodes = []\n",
    "for drug_idx, row in encoded_atc_codes_df.iterrows():\n",
    "    for atc_code_idx in range(len(row)):\n",
    "        if row[atc_code_idx] == 1:\n",
    "            source_nodes.append(drug_idx)\n",
    "            target_nodes.append(atc_code_idx)\n",
    "data_small['drug', 'isClassifiedAs', 'atc_code'].edge_index = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "\n",
    "# Create edge lists for drug-to-target relationships\n",
    "source_nodes = []\n",
    "target_nodes = []\n",
    "for drug_idx, row in encoded_targets_df.iterrows():\n",
    "    for target_idx in range(len(row)):\n",
    "        if row[target_idx] == 1:\n",
    "            source_nodes.append(drug_idx)\n",
    "            target_nodes.append(target_idx)\n",
    "data_small['drug', 'targets', 'target'].edge_index = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "\n",
    "# Create edge lists for drug-to-doping relationships\n",
    "source_nodes = []\n",
    "target_nodes = []\n",
    "for drug_idx, doping in enumerate(encoded_doping_df['Doping']):\n",
    "    source_nodes.append(drug_idx)\n",
    "    target_nodes.append(doping)\n",
    "data_small['drug', 'isDoping', 'doping'].edge_index = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "\n",
    "# Create edge lists for drug-to-drug interactions\n",
    "source_nodes = []\n",
    "target_nodes = []\n",
    "for drug_idx, row in encoded_interactions_df.iterrows():\n",
    "    for target_idx in range(len(row)):\n",
    "        if row[target_idx] == 1:\n",
    "            source_nodes.append(drug_idx)\n",
    "            target_nodes.append(target_idx)\n",
    "data_small['drug', 'interactsWith', 'drug'].edge_index = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "\n",
    "print(data_small)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "338"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_drugbank_id_df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(40) tensor(298) tensor(0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.transforms import RandomNodeSplit\n",
    "\n",
    "# Load encoded data from CSV files and convert to tensors (omitted for brevity)\n",
    "# Initialize HeteroData and add nodes and edges (omitted for brevity)\n",
    "\n",
    "# Add doping labels to the drug nodes\n",
    "data_small['drug'].y = torch.tensor(encoded_doping_df['Doping'].values, dtype=torch.long)\n",
    "\n",
    "# Perform a node-level random split\n",
    "transform = RandomNodeSplit(split='random', num_splits=1)\n",
    "data_small = transform(data_small)\n",
    "\n",
    "# Verify masks\n",
    "print(data_small['drug'].train_mask.sum(), data_small['drug'].val_mask.sum(), data_small['drug'].test_mask.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import HeteroConv, SAGEConv, Linear\n",
    "\n",
    "class HeteroGNN1(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super(HeteroGNN1, self).__init__()\n",
    "        self.conv1 = HeteroConv({\n",
    "            ('drug', 'isInCategory', 'drug_category'): SAGEConv((-1, -1), hidden_channels),\n",
    "            ('drug', 'isClassifiedAs', 'atc_code'): SAGEConv((-1, -1), hidden_channels),\n",
    "            ('drug', 'targets', 'target'): SAGEConv((-1, -1), hidden_channels),\n",
    "            ('drug', 'isDoping', 'doping'): SAGEConv((-1, -1), hidden_channels),\n",
    "            ('drug', 'interactsWith', 'drug'): SAGEConv((-1, -1), hidden_channels),\n",
    "        }, aggr='sum')\n",
    "        self.lin = Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x_dict = self.conv1(x_dict, edge_index_dict)\n",
    "        x_dict = {key: F.relu(x) for key, x in x_dict.items()}\n",
    "        return self.lin(x_dict['drug'])\n",
    "\n",
    "model1 = HeteroGNN1(hidden_channels=64, out_channels=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.9811, Train Acc: 0.5500, Val Acc: 0.3826\n",
      "Epoch: 002, Loss: 2.6032, Train Acc: 0.5000, Val Acc: 0.6342\n",
      "Epoch: 003, Loss: 7.2715, Train Acc: 0.5000, Val Acc: 0.6477\n",
      "Epoch: 004, Loss: 4.7531, Train Acc: 0.5000, Val Acc: 0.4396\n",
      "Epoch: 005, Loss: 1.3754, Train Acc: 0.5000, Val Acc: 0.3658\n",
      "Epoch: 006, Loss: 3.3175, Train Acc: 0.5250, Val Acc: 0.3859\n",
      "Epoch: 007, Loss: 2.0312, Train Acc: 0.6000, Val Acc: 0.4799\n",
      "Epoch: 008, Loss: 1.0818, Train Acc: 0.6500, Val Acc: 0.6007\n",
      "Epoch: 009, Loss: 1.6187, Train Acc: 0.6250, Val Acc: 0.6275\n",
      "Epoch: 010, Loss: 1.7635, Train Acc: 0.6750, Val Acc: 0.5805\n",
      "Epoch: 011, Loss: 1.3000, Train Acc: 0.6500, Val Acc: 0.4966\n",
      "Epoch: 012, Loss: 0.8333, Train Acc: 0.5250, Val Acc: 0.3993\n",
      "Epoch: 013, Loss: 0.8998, Train Acc: 0.5750, Val Acc: 0.3893\n",
      "Epoch: 014, Loss: 1.1544, Train Acc: 0.6000, Val Acc: 0.3926\n",
      "Epoch: 015, Loss: 1.0189, Train Acc: 0.6500, Val Acc: 0.3960\n",
      "Epoch: 016, Loss: 0.7029, Train Acc: 0.7000, Val Acc: 0.5268\n",
      "Epoch: 017, Loss: 0.6086, Train Acc: 0.6750, Val Acc: 0.6208\n",
      "Epoch: 018, Loss: 0.7139, Train Acc: 0.5750, Val Acc: 0.6443\n",
      "Epoch: 019, Loss: 0.7923, Train Acc: 0.5750, Val Acc: 0.6443\n",
      "Epoch: 020, Loss: 0.7530, Train Acc: 0.6000, Val Acc: 0.6443\n",
      "Epoch: 021, Loss: 0.6419, Train Acc: 0.7000, Val Acc: 0.5940\n",
      "Epoch: 022, Loss: 0.5599, Train Acc: 0.8000, Val Acc: 0.4664\n",
      "Epoch: 023, Loss: 0.5718, Train Acc: 0.6250, Val Acc: 0.4228\n",
      "Epoch: 024, Loss: 0.6304, Train Acc: 0.6000, Val Acc: 0.4027\n",
      "Epoch: 025, Loss: 0.6538, Train Acc: 0.6000, Val Acc: 0.4060\n",
      "Epoch: 026, Loss: 0.6236, Train Acc: 0.7500, Val Acc: 0.4564\n",
      "Epoch: 027, Loss: 0.5746, Train Acc: 0.7500, Val Acc: 0.5772\n",
      "Epoch: 028, Loss: 0.5478, Train Acc: 0.6250, Val Acc: 0.5805\n",
      "Epoch: 029, Loss: 0.5556, Train Acc: 0.6250, Val Acc: 0.5973\n",
      "Epoch: 030, Loss: 0.5790, Train Acc: 0.6500, Val Acc: 0.5973\n",
      "Epoch: 031, Loss: 0.5926, Train Acc: 0.6500, Val Acc: 0.5973\n",
      "Epoch: 032, Loss: 0.5865, Train Acc: 0.6500, Val Acc: 0.5940\n",
      "Epoch: 033, Loss: 0.5660, Train Acc: 0.6750, Val Acc: 0.5940\n",
      "Epoch: 034, Loss: 0.5451, Train Acc: 0.7750, Val Acc: 0.5336\n",
      "Epoch: 035, Loss: 0.5349, Train Acc: 0.8000, Val Acc: 0.5235\n",
      "Epoch: 036, Loss: 0.5393, Train Acc: 0.7750, Val Acc: 0.4530\n",
      "Epoch: 037, Loss: 0.5483, Train Acc: 0.7250, Val Acc: 0.4497\n",
      "Epoch: 038, Loss: 0.5497, Train Acc: 0.7750, Val Acc: 0.4732\n",
      "Epoch: 039, Loss: 0.5373, Train Acc: 0.8000, Val Acc: 0.4933\n",
      "Epoch: 040, Loss: 0.5252, Train Acc: 0.8000, Val Acc: 0.5201\n",
      "Epoch: 041, Loss: 0.5171, Train Acc: 0.8000, Val Acc: 0.5336\n",
      "Epoch: 042, Loss: 0.5136, Train Acc: 0.7000, Val Acc: 0.5671\n",
      "Epoch: 043, Loss: 0.5120, Train Acc: 0.7000, Val Acc: 0.5671\n",
      "Epoch: 044, Loss: 0.5103, Train Acc: 0.7250, Val Acc: 0.5570\n",
      "Epoch: 045, Loss: 0.5052, Train Acc: 0.7250, Val Acc: 0.5369\n",
      "Epoch: 046, Loss: 0.4952, Train Acc: 0.7250, Val Acc: 0.5336\n",
      "Epoch: 047, Loss: 0.4814, Train Acc: 0.7250, Val Acc: 0.5168\n",
      "Epoch: 048, Loss: 0.4724, Train Acc: 0.8000, Val Acc: 0.5201\n",
      "Epoch: 049, Loss: 0.4716, Train Acc: 0.8000, Val Acc: 0.5067\n",
      "Epoch: 050, Loss: 0.4725, Train Acc: 0.8000, Val Acc: 0.5101\n",
      "Epoch: 051, Loss: 0.4647, Train Acc: 0.8250, Val Acc: 0.5101\n",
      "Epoch: 052, Loss: 0.4526, Train Acc: 0.8000, Val Acc: 0.5268\n",
      "Epoch: 053, Loss: 0.4445, Train Acc: 0.7250, Val Acc: 0.5201\n",
      "Epoch: 054, Loss: 0.4420, Train Acc: 0.7250, Val Acc: 0.5235\n",
      "Epoch: 055, Loss: 0.4399, Train Acc: 0.7250, Val Acc: 0.5268\n",
      "Epoch: 056, Loss: 0.4331, Train Acc: 0.8000, Val Acc: 0.5235\n",
      "Epoch: 057, Loss: 0.4230, Train Acc: 0.8250, Val Acc: 0.5134\n",
      "Epoch: 058, Loss: 0.4150, Train Acc: 0.8250, Val Acc: 0.5101\n",
      "Epoch: 059, Loss: 0.4103, Train Acc: 0.8500, Val Acc: 0.5201\n",
      "Epoch: 060, Loss: 0.4054, Train Acc: 0.8250, Val Acc: 0.5101\n",
      "Epoch: 061, Loss: 0.3975, Train Acc: 0.8250, Val Acc: 0.5201\n",
      "Epoch: 062, Loss: 0.3885, Train Acc: 0.7750, Val Acc: 0.5235\n",
      "Epoch: 063, Loss: 0.3814, Train Acc: 0.8000, Val Acc: 0.5235\n",
      "Epoch: 064, Loss: 0.3755, Train Acc: 0.8250, Val Acc: 0.5268\n",
      "Epoch: 065, Loss: 0.3679, Train Acc: 0.9000, Val Acc: 0.5235\n",
      "Epoch: 066, Loss: 0.3591, Train Acc: 0.8750, Val Acc: 0.5201\n",
      "Epoch: 067, Loss: 0.3520, Train Acc: 0.8750, Val Acc: 0.5101\n",
      "Epoch: 068, Loss: 0.3461, Train Acc: 0.8750, Val Acc: 0.5134\n",
      "Epoch: 069, Loss: 0.3381, Train Acc: 0.9000, Val Acc: 0.5302\n",
      "Epoch: 070, Loss: 0.3297, Train Acc: 0.9250, Val Acc: 0.5268\n",
      "Epoch: 071, Loss: 0.3236, Train Acc: 0.9250, Val Acc: 0.5268\n",
      "Epoch: 072, Loss: 0.3177, Train Acc: 0.9250, Val Acc: 0.5336\n",
      "Epoch: 073, Loss: 0.3102, Train Acc: 0.9000, Val Acc: 0.5268\n",
      "Epoch: 074, Loss: 0.3027, Train Acc: 0.9000, Val Acc: 0.5235\n",
      "Epoch: 075, Loss: 0.2972, Train Acc: 0.9000, Val Acc: 0.5201\n",
      "Epoch: 076, Loss: 0.2911, Train Acc: 0.9000, Val Acc: 0.5201\n",
      "Epoch: 077, Loss: 0.2837, Train Acc: 0.9250, Val Acc: 0.5336\n",
      "Epoch: 078, Loss: 0.2770, Train Acc: 0.9500, Val Acc: 0.5302\n",
      "Epoch: 079, Loss: 0.2715, Train Acc: 0.9250, Val Acc: 0.5302\n",
      "Epoch: 080, Loss: 0.2648, Train Acc: 0.9000, Val Acc: 0.5134\n",
      "Epoch: 081, Loss: 0.2585, Train Acc: 0.9000, Val Acc: 0.5168\n",
      "Epoch: 082, Loss: 0.2533, Train Acc: 0.9000, Val Acc: 0.5168\n",
      "Epoch: 083, Loss: 0.2474, Train Acc: 0.9000, Val Acc: 0.5201\n",
      "Epoch: 084, Loss: 0.2414, Train Acc: 0.9250, Val Acc: 0.5268\n",
      "Epoch: 085, Loss: 0.2361, Train Acc: 0.9250, Val Acc: 0.5201\n",
      "Epoch: 086, Loss: 0.2307, Train Acc: 0.9250, Val Acc: 0.5235\n",
      "Epoch: 087, Loss: 0.2254, Train Acc: 0.9250, Val Acc: 0.5302\n",
      "Epoch: 088, Loss: 0.2206, Train Acc: 0.9250, Val Acc: 0.5302\n",
      "Epoch: 089, Loss: 0.2156, Train Acc: 0.9250, Val Acc: 0.5235\n",
      "Epoch: 090, Loss: 0.2109, Train Acc: 0.9750, Val Acc: 0.5235\n",
      "Epoch: 091, Loss: 0.2067, Train Acc: 0.9500, Val Acc: 0.5268\n",
      "Epoch: 092, Loss: 0.2019, Train Acc: 0.9500, Val Acc: 0.5336\n",
      "Epoch: 093, Loss: 0.1974, Train Acc: 0.9500, Val Acc: 0.5302\n",
      "Epoch: 094, Loss: 0.1933, Train Acc: 0.9750, Val Acc: 0.5302\n",
      "Epoch: 095, Loss: 0.1891, Train Acc: 1.0000, Val Acc: 0.5302\n",
      "Epoch: 096, Loss: 0.1851, Train Acc: 1.0000, Val Acc: 0.5336\n",
      "Epoch: 097, Loss: 0.1810, Train Acc: 0.9750, Val Acc: 0.5268\n",
      "Epoch: 098, Loss: 0.1771, Train Acc: 0.9750, Val Acc: 0.5302\n",
      "Epoch: 099, Loss: 0.1734, Train Acc: 0.9750, Val Acc: 0.5302\n",
      "Epoch: 100, Loss: 0.1694, Train Acc: 1.0000, Val Acc: 0.5268\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 28>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m     val_acc \u001b[38;5;241m=\u001b[39m test(data_small[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrug\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mval_mask)\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m03d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m test_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_small\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdrug\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36mtest\u001b[1;34m(mask)\u001b[0m\n\u001b[0;32m     18\u001b[0m pred \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     19\u001b[0m correct \u001b[38;5;241m=\u001b[39m pred[mask] \u001b[38;5;241m==\u001b[39m data_small[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrug\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39my[mask]\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcorrect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "# Define optimizer and loss function\n",
    "optimizer = torch.optim.Adam(model1.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    model1.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model1(data_small.x_dict, data_small.edge_index_dict)\n",
    "    loss = criterion(out[data_small['drug'].train_mask], data_small['drug'].y[data_small['drug'].train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def test(mask):\n",
    "    model1.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model1(data_small.x_dict, data_small.edge_index_dict)\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct = pred[mask] == data_small['drug'].y[mask]\n",
    "        return int(correct.sum()) / int(mask.sum())\n",
    "\n",
    "for epoch in range(1, 101):\n",
    "    loss = train()\n",
    "    train_acc = test(data_small['drug'].train_mask)\n",
    "    val_acc = test(data_small['drug'].val_mask)\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "test_acc = test(data_small['drug'].test_mask)\n",
    "print(f'Test Acc: {test_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train mask sum: 40\n",
      "Val mask sum: 200\n",
      "Test mask sum: 98\n",
      "Epoch: 001, Loss: 1.7704, Train Acc: 0.5000, Val Acc: 0.3700\n",
      "Epoch: 002, Loss: 15.8405, Train Acc: 0.5000, Val Acc: 0.3700\n",
      "Epoch: 003, Loss: 10.4824, Train Acc: 0.5000, Val Acc: 0.3700\n",
      "Epoch: 004, Loss: 3.0849, Train Acc: 0.5000, Val Acc: 0.6300\n",
      "Epoch: 005, Loss: 3.5898, Train Acc: 0.5000, Val Acc: 0.6300\n",
      "Epoch: 006, Loss: 4.7413, Train Acc: 0.5000, Val Acc: 0.6300\n",
      "Epoch: 007, Loss: 3.8613, Train Acc: 0.5000, Val Acc: 0.6300\n",
      "Epoch: 008, Loss: 2.0971, Train Acc: 0.6000, Val Acc: 0.5250\n",
      "Epoch: 009, Loss: 0.6750, Train Acc: 0.5250, Val Acc: 0.3700\n",
      "Epoch: 010, Loss: 1.1810, Train Acc: 0.5250, Val Acc: 0.3750\n",
      "Epoch: 011, Loss: 1.6749, Train Acc: 0.5250, Val Acc: 0.3750\n",
      "Epoch: 012, Loss: 1.7238, Train Acc: 0.5250, Val Acc: 0.3850\n",
      "Epoch: 013, Loss: 1.4627, Train Acc: 0.5250, Val Acc: 0.3650\n",
      "Epoch: 014, Loss: 1.0560, Train Acc: 0.5750, Val Acc: 0.3750\n",
      "Epoch: 015, Loss: 0.7090, Train Acc: 0.7000, Val Acc: 0.5000\n",
      "Epoch: 016, Loss: 0.6318, Train Acc: 0.5250, Val Acc: 0.6400\n",
      "Epoch: 017, Loss: 0.7804, Train Acc: 0.5000, Val Acc: 0.6350\n",
      "Epoch: 018, Loss: 0.9344, Train Acc: 0.5000, Val Acc: 0.6300\n",
      "Epoch: 019, Loss: 0.9928, Train Acc: 0.5000, Val Acc: 0.6300\n",
      "Epoch: 020, Loss: 0.9534, Train Acc: 0.5000, Val Acc: 0.6350\n",
      "Epoch: 021, Loss: 0.8535, Train Acc: 0.5000, Val Acc: 0.6350\n",
      "Epoch: 022, Loss: 0.7413, Train Acc: 0.6000, Val Acc: 0.6600\n",
      "Epoch: 023, Loss: 0.6586, Train Acc: 0.6250, Val Acc: 0.4600\n",
      "Epoch: 024, Loss: 0.6245, Train Acc: 0.5750, Val Acc: 0.4150\n",
      "Epoch: 025, Loss: 0.6323, Train Acc: 0.5750, Val Acc: 0.3850\n",
      "Epoch: 026, Loss: 0.6603, Train Acc: 0.5750, Val Acc: 0.3750\n",
      "Epoch: 027, Loss: 0.6889, Train Acc: 0.5500, Val Acc: 0.3750\n",
      "Epoch: 028, Loss: 0.7059, Train Acc: 0.5500, Val Acc: 0.3750\n",
      "Epoch: 029, Loss: 0.7074, Train Acc: 0.5500, Val Acc: 0.3750\n",
      "Epoch: 030, Loss: 0.6956, Train Acc: 0.5750, Val Acc: 0.3750\n",
      "Epoch: 031, Loss: 0.6757, Train Acc: 0.5750, Val Acc: 0.3850\n",
      "Epoch: 032, Loss: 0.6537, Train Acc: 0.5750, Val Acc: 0.4000\n",
      "Epoch: 033, Loss: 0.6347, Train Acc: 0.6000, Val Acc: 0.4050\n",
      "Epoch: 034, Loss: 0.6216, Train Acc: 0.6500, Val Acc: 0.4500\n",
      "Epoch: 035, Loss: 0.6153, Train Acc: 0.7250, Val Acc: 0.4850\n",
      "Epoch: 036, Loss: 0.6143, Train Acc: 0.7500, Val Acc: 0.5450\n",
      "Epoch: 037, Loss: 0.6166, Train Acc: 0.7750, Val Acc: 0.5650\n",
      "Epoch: 038, Loss: 0.6205, Train Acc: 0.7250, Val Acc: 0.6200\n",
      "Epoch: 039, Loss: 0.6244, Train Acc: 0.5750, Val Acc: 0.6500\n",
      "Epoch: 040, Loss: 0.6268, Train Acc: 0.5750, Val Acc: 0.6650\n",
      "Epoch: 041, Loss: 0.6267, Train Acc: 0.6250, Val Acc: 0.6700\n",
      "Epoch: 042, Loss: 0.6243, Train Acc: 0.6750, Val Acc: 0.6400\n",
      "Epoch: 043, Loss: 0.6196, Train Acc: 0.7250, Val Acc: 0.6350\n",
      "Epoch: 044, Loss: 0.6135, Train Acc: 0.7750, Val Acc: 0.5850\n",
      "Epoch: 045, Loss: 0.6068, Train Acc: 0.7750, Val Acc: 0.5550\n",
      "Epoch: 046, Loss: 0.6001, Train Acc: 0.8250, Val Acc: 0.4900\n",
      "Epoch: 047, Loss: 0.5944, Train Acc: 0.7250, Val Acc: 0.4900\n",
      "Epoch: 048, Loss: 0.5899, Train Acc: 0.7000, Val Acc: 0.4850\n",
      "Epoch: 049, Loss: 0.5867, Train Acc: 0.6500, Val Acc: 0.4750\n",
      "Epoch: 050, Loss: 0.5846, Train Acc: 0.6500, Val Acc: 0.4700\n",
      "Epoch: 051, Loss: 0.5833, Train Acc: 0.6750, Val Acc: 0.4650\n",
      "Epoch: 052, Loss: 0.5822, Train Acc: 0.6750, Val Acc: 0.4550\n",
      "Epoch: 053, Loss: 0.5807, Train Acc: 0.6500, Val Acc: 0.4650\n",
      "Epoch: 054, Loss: 0.5782, Train Acc: 0.6500, Val Acc: 0.4700\n",
      "Epoch: 055, Loss: 0.5746, Train Acc: 0.6500, Val Acc: 0.4650\n",
      "Epoch: 056, Loss: 0.5699, Train Acc: 0.7000, Val Acc: 0.4750\n",
      "Epoch: 057, Loss: 0.5648, Train Acc: 0.7250, Val Acc: 0.4750\n",
      "Epoch: 058, Loss: 0.5597, Train Acc: 0.7500, Val Acc: 0.4900\n",
      "Epoch: 059, Loss: 0.5552, Train Acc: 0.7750, Val Acc: 0.5000\n",
      "Epoch: 060, Loss: 0.5516, Train Acc: 0.7750, Val Acc: 0.5150\n",
      "Epoch: 061, Loss: 0.5489, Train Acc: 0.8000, Val Acc: 0.5200\n",
      "Epoch: 062, Loss: 0.5467, Train Acc: 0.8250, Val Acc: 0.5450\n",
      "Epoch: 063, Loss: 0.5446, Train Acc: 0.8000, Val Acc: 0.5550\n",
      "Epoch: 064, Loss: 0.5420, Train Acc: 0.8000, Val Acc: 0.5550\n",
      "Epoch: 065, Loss: 0.5386, Train Acc: 0.8250, Val Acc: 0.5400\n",
      "Epoch: 066, Loss: 0.5346, Train Acc: 0.8000, Val Acc: 0.5300\n",
      "Epoch: 067, Loss: 0.5305, Train Acc: 0.7750, Val Acc: 0.5150\n",
      "Epoch: 068, Loss: 0.5268, Train Acc: 0.7750, Val Acc: 0.5250\n",
      "Epoch: 069, Loss: 0.5236, Train Acc: 0.7750, Val Acc: 0.5200\n",
      "Epoch: 070, Loss: 0.5209, Train Acc: 0.7500, Val Acc: 0.5250\n",
      "Epoch: 071, Loss: 0.5183, Train Acc: 0.7500, Val Acc: 0.5200\n",
      "Epoch: 072, Loss: 0.5156, Train Acc: 0.7750, Val Acc: 0.5200\n",
      "Epoch: 073, Loss: 0.5126, Train Acc: 0.7750, Val Acc: 0.5300\n",
      "Epoch: 074, Loss: 0.5094, Train Acc: 0.7750, Val Acc: 0.5250\n",
      "Epoch: 075, Loss: 0.5063, Train Acc: 0.8000, Val Acc: 0.5200\n",
      "Epoch: 076, Loss: 0.5032, Train Acc: 0.8000, Val Acc: 0.5250\n",
      "Epoch: 077, Loss: 0.5005, Train Acc: 0.8250, Val Acc: 0.5250\n",
      "Epoch: 078, Loss: 0.4978, Train Acc: 0.8250, Val Acc: 0.5250\n",
      "Epoch: 079, Loss: 0.4951, Train Acc: 0.8250, Val Acc: 0.5250\n",
      "Epoch: 080, Loss: 0.4920, Train Acc: 0.8250, Val Acc: 0.5200\n",
      "Epoch: 081, Loss: 0.4889, Train Acc: 0.8000, Val Acc: 0.5200\n",
      "Epoch: 082, Loss: 0.4857, Train Acc: 0.8000, Val Acc: 0.5300\n",
      "Epoch: 083, Loss: 0.4827, Train Acc: 0.8000, Val Acc: 0.5300\n",
      "Epoch: 084, Loss: 0.4800, Train Acc: 0.8250, Val Acc: 0.5300\n",
      "Epoch: 085, Loss: 0.4772, Train Acc: 0.8250, Val Acc: 0.5200\n",
      "Epoch: 086, Loss: 0.4742, Train Acc: 0.8250, Val Acc: 0.5250\n",
      "Epoch: 087, Loss: 0.4710, Train Acc: 0.8500, Val Acc: 0.5350\n",
      "Epoch: 088, Loss: 0.4678, Train Acc: 0.8250, Val Acc: 0.5350\n",
      "Epoch: 089, Loss: 0.4648, Train Acc: 0.8500, Val Acc: 0.5400\n",
      "Epoch: 090, Loss: 0.4618, Train Acc: 0.8500, Val Acc: 0.5250\n",
      "Epoch: 091, Loss: 0.4588, Train Acc: 0.8500, Val Acc: 0.5150\n",
      "Epoch: 092, Loss: 0.4555, Train Acc: 0.8500, Val Acc: 0.5100\n",
      "Epoch: 093, Loss: 0.4522, Train Acc: 0.8500, Val Acc: 0.4950\n",
      "Epoch: 094, Loss: 0.4490, Train Acc: 0.8250, Val Acc: 0.4900\n",
      "Epoch: 095, Loss: 0.4458, Train Acc: 0.8250, Val Acc: 0.4850\n",
      "Epoch: 096, Loss: 0.4425, Train Acc: 0.8250, Val Acc: 0.4950\n",
      "Epoch: 097, Loss: 0.4392, Train Acc: 0.8500, Val Acc: 0.5050\n",
      "Epoch: 098, Loss: 0.4357, Train Acc: 0.8500, Val Acc: 0.5050\n",
      "Epoch: 099, Loss: 0.4323, Train Acc: 0.8500, Val Acc: 0.5150\n",
      "Epoch: 100, Loss: 0.4288, Train Acc: 0.8500, Val Acc: 0.5200\n",
      "Test Acc: 0.5510\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.transforms import RandomNodeSplit\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import HeteroConv, SAGEConv, Linear\n",
    "\n",
    "# Load encoded data from CSV files and convert to tensors (omitted for brevity)\n",
    "# Initialize HeteroData and add nodes and edges (omitted for brevity)\n",
    "\n",
    "# Add doping labels to the drug nodes\n",
    "data_small['drug'].y = torch.tensor(encoded_doping_df['Doping'].values, dtype=torch.long)\n",
    "\n",
    "# Perform a node-level random split with ensured allocation\n",
    "transform = RandomNodeSplit(split='random', num_train_per_class=20, num_val=200, num_test=100)\n",
    "data_small = transform(data_small)\n",
    "\n",
    "# Verify masks\n",
    "print('Train mask sum:', data_small['drug'].train_mask.sum().item())\n",
    "print('Val mask sum:', data_small['drug'].val_mask.sum().item())\n",
    "print('Test mask sum:', data_small['drug'].test_mask.sum().item())\n",
    "\n",
    "class HeteroGNN1(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super(HeteroGNN1, self).__init__()\n",
    "        self.conv1 = HeteroConv({\n",
    "            ('drug', 'isInCategory', 'drug_category'): SAGEConv((-1, -1), hidden_channels),\n",
    "            ('drug', 'isClassifiedAs', 'atc_code'): SAGEConv((-1, -1), hidden_channels),\n",
    "            ('drug', 'targets', 'target'): SAGEConv((-1, -1), hidden_channels),\n",
    "            ('drug', 'isDoping', 'doping'): SAGEConv((-1, -1), hidden_channels),\n",
    "            ('drug', 'interactsWith', 'drug'): SAGEConv((-1, -1), hidden_channels),\n",
    "        }, aggr='sum')\n",
    "        self.lin = Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x_dict = self.conv1(x_dict, edge_index_dict)\n",
    "        x_dict = {key: F.relu(x) for key, x in x_dict.items()}\n",
    "        return self.lin(x_dict['drug'])\n",
    "\n",
    "model1 = HeteroGNN1(hidden_channels=64, out_channels=2)\n",
    "# Define optimizer and loss function\n",
    "optimizer = torch.optim.Adam(model1.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    model1.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model1(data_small.x_dict, data_small.edge_index_dict)\n",
    "    loss = criterion(out[data_small['drug'].train_mask], data_small['drug'].y[data_small['drug'].train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def test(mask):\n",
    "    model1.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model1(data_small.x_dict, data_small.edge_index_dict)\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct = pred[mask] == data_small['drug'].y[mask]\n",
    "        if int(mask.sum()) == 0:  # Check to avoid division by zero\n",
    "            return float('nan')\n",
    "        return int(correct.sum()) / int(mask.sum())\n",
    "\n",
    "for epoch in range(1, 101):\n",
    "    loss = train()\n",
    "    train_acc = test(data_small['drug'].train_mask)\n",
    "    val_acc = test(data_small['drug'].val_mask)\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "test_acc = test(data_small['drug'].test_mask)\n",
    "print(f'Test Acc: {test_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  drug={\n",
      "    x=[338, 467],\n",
      "    y=[338],\n",
      "    train_mask=[338],\n",
      "    val_mask=[338],\n",
      "    test_mask=[338],\n",
      "  },\n",
      "  drug_category={ x=[1095, 1095] },\n",
      "  atc_code={ x=[974, 974] },\n",
      "  target={ x=[249, 249] },\n",
      "  doping={ x=[2, 2] },\n",
      "  (drug, isInCategory, drug_category)={\n",
      "    edge_index=[2, 7096],\n",
      "    edge_label=[7096],\n",
      "    edge_label_index=[2, 7096],\n",
      "  },\n",
      "  (drug, isClassifiedAs, atc_code)={\n",
      "    edge_index=[2, 1896],\n",
      "    edge_label=[1896],\n",
      "    edge_label_index=[2, 1896],\n",
      "  },\n",
      "  (drug, targets, target)={\n",
      "    edge_index=[2, 289],\n",
      "    edge_label=[289],\n",
      "    edge_label_index=[2, 289],\n",
      "  },\n",
      "  (drug, isDoping, doping)={\n",
      "    edge_index=[2, 289],\n",
      "    edge_label=[289],\n",
      "    edge_label_index=[2, 289],\n",
      "  },\n",
      "  (drug, interactsWith, drug)={\n",
      "    edge_index=[2, 54438],\n",
      "    edge_label=[54438],\n",
      "    edge_label_index=[2, 54438],\n",
      "  },\n",
      "  (drug_category, rev_isInCategory, drug)={ edge_index=[2, 8347] },\n",
      "  (atc_code, rev_isClassifiedAs, drug)={ edge_index=[2, 2229] },\n",
      "  (target, rev_targets, drug)={ edge_index=[2, 338] },\n",
      "  (doping, rev_isDoping, drug)={ edge_index=[2, 338] }\n",
      ")\n",
      "HeteroData(\n",
      "  drug={\n",
      "    x=[338, 467],\n",
      "    y=[338],\n",
      "    train_mask=[338],\n",
      "    val_mask=[338],\n",
      "    test_mask=[338],\n",
      "  },\n",
      "  drug_category={ x=[1095, 1095] },\n",
      "  atc_code={ x=[974, 974] },\n",
      "  target={ x=[249, 249] },\n",
      "  doping={ x=[2, 2] },\n",
      "  (drug, isInCategory, drug_category)={\n",
      "    edge_index=[2, 7096],\n",
      "    edge_label=[417],\n",
      "    edge_label_index=[2, 417],\n",
      "  },\n",
      "  (drug, isClassifiedAs, atc_code)={\n",
      "    edge_index=[2, 1896],\n",
      "    edge_label=[111],\n",
      "    edge_label_index=[2, 111],\n",
      "  },\n",
      "  (drug, targets, target)={\n",
      "    edge_index=[2, 289],\n",
      "    edge_label=[16],\n",
      "    edge_label_index=[2, 16],\n",
      "  },\n",
      "  (drug, isDoping, doping)={\n",
      "    edge_index=[2, 289],\n",
      "    edge_label=[16],\n",
      "    edge_label_index=[2, 16],\n",
      "  },\n",
      "  (drug, interactsWith, drug)={\n",
      "    edge_index=[2, 54438],\n",
      "    edge_label=[3202],\n",
      "    edge_label_index=[2, 3202],\n",
      "  },\n",
      "  (drug_category, rev_isInCategory, drug)={ edge_index=[2, 8347] },\n",
      "  (atc_code, rev_isClassifiedAs, drug)={ edge_index=[2, 2229] },\n",
      "  (target, rev_targets, drug)={ edge_index=[2, 338] },\n",
      "  (doping, rev_isDoping, drug)={ edge_index=[2, 338] }\n",
      ")\n",
      "HeteroData(\n",
      "  drug={\n",
      "    x=[338, 467],\n",
      "    y=[338],\n",
      "    train_mask=[338],\n",
      "    val_mask=[338],\n",
      "    test_mask=[338],\n",
      "  },\n",
      "  drug_category={ x=[1095, 1095] },\n",
      "  atc_code={ x=[974, 974] },\n",
      "  target={ x=[249, 249] },\n",
      "  doping={ x=[2, 2] },\n",
      "  (drug, isInCategory, drug_category)={\n",
      "    edge_index=[2, 7513],\n",
      "    edge_label=[834],\n",
      "    edge_label_index=[2, 834],\n",
      "  },\n",
      "  (drug, isClassifiedAs, atc_code)={\n",
      "    edge_index=[2, 2007],\n",
      "    edge_label=[222],\n",
      "    edge_label_index=[2, 222],\n",
      "  },\n",
      "  (drug, targets, target)={\n",
      "    edge_index=[2, 305],\n",
      "    edge_label=[33],\n",
      "    edge_label_index=[2, 33],\n",
      "  },\n",
      "  (drug, isDoping, doping)={\n",
      "    edge_index=[2, 305],\n",
      "    edge_label=[33],\n",
      "    edge_label_index=[2, 33],\n",
      "  },\n",
      "  (drug, interactsWith, drug)={\n",
      "    edge_index=[2, 57640],\n",
      "    edge_label=[6404],\n",
      "    edge_label_index=[2, 6404],\n",
      "  },\n",
      "  (drug_category, rev_isInCategory, drug)={ edge_index=[2, 8347] },\n",
      "  (atc_code, rev_isClassifiedAs, drug)={ edge_index=[2, 2229] },\n",
      "  (target, rev_targets, drug)={ edge_index=[2, 338] },\n",
      "  (doping, rev_isDoping, drug)={ edge_index=[2, 338] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.transforms import ToUndirected, RandomLinkSplit\n",
    "# Make the graph undirected and remove reverse edge labels\n",
    "data = ToUndirected()(data_small)\n",
    "\n",
    "# Perform a link-level split into training, validation, and test edges\n",
    "transform = RandomLinkSplit(\n",
    "    num_val=0.05,\n",
    "    num_test=0.1,\n",
    "    neg_sampling_ratio=0.0,\n",
    "    edge_types=[('drug', 'isInCategory', 'drug_category'),\n",
    "                ('drug', 'isClassifiedAs', 'atc_code'),\n",
    "                ('drug', 'targets', 'target'),\n",
    "                ('drug', 'isDoping', 'doping'),\n",
    "                ('drug', 'interactsWith', 'drug')],\n",
    ")\n",
    "train_data, val_data, test_data = transform(data)\n",
    "\n",
    "print(train_data)\n",
    "print(val_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('hetero.csv')\n",
    "\n",
    "# Extract the set of valid DrugBank IDs\n",
    "valid_drugbank_ids = set(df['DrugBank ID'])\n",
    "\n",
    "# Function to clean the values in a column\n",
    "def clean_values(column):\n",
    "    def clean_cell(cell):\n",
    "        if pd.isna(cell):\n",
    "            return cell\n",
    "        ids = cell.split('; ')\n",
    "        valid_ids = [drug_id for drug_id in ids if drug_id in valid_drugbank_ids]\n",
    "        return '; '.join(valid_ids)\n",
    "    \n",
    "    return column.apply(clean_cell)\n",
    "\n",
    "# Clean the 'Interactions' and 'Similar Structure' columns\n",
    "df['Interactions'] = clean_values(df['Interactions'])\n",
    "df['Similar Structure'] = clean_values(df['Similar Structure'])\n",
    "\n",
    "# Save the cleaned DataFrame back to CSV\n",
    "df.to_csv('cleaned_hetero.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
